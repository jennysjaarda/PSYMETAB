---
title: "Genetic data quality control and processing"
site: workflowr::wflow_site
output:
  workflowr::wflow_html:
    toc: true
---

```{css include=FALSE}
pre code, pre, code {
  white-space: pre !important;
  overflow-x: scroll !important;
  word-break: keep-all !important;
  word-wrap: initial !important;
}
options(width = 150)
```

**The following document outlines and summarizes the genetic quality control and processing procedure that was followed to create a clean, imputed dataset.**
	
# Step 1: Prepare and cluster genomestudio files.
	
*Step 1 was performed entirely on CHUV computer*
	
## Part A: Randomize IDs.
	
- Genetic sampleIDs were recoded according to GPCR algorithm to ensure genetic participants are not identifiable.
- `code/radomize_IDs.r` was run on CHUV computer before building GenomeStudio project.
- Creates a new csv file which was used to create a GenomeStudio project with data provided by lab in Geneva.
- Requires manual addition of header before uploading to GenomeStudio.

```{r eval=FALSE}

[Header],,,,,,,,,,,,,
Investigator Name,,,,,,,,,,,,,
Project Name,,,,,,,,,,,,,
Experiment Name,,,,,,,,,,,,,
Date,,,,,,,,,,,,,
[Manifests],,,,,,,,,,,,,
A,GSA_UPPC_20023490X357589_A1,,,,,,,,,,,,
[Data],,,,,,,,,,,,,

```

- Some samples were found to be duplicates (i.e. 2 samples at 2 different time points were analyzed for the same individual) and they were recoded to have ID as: `${ID}002`.

## Part B: Create GenomeStudio files.


- Instructions can be found [here](https://support.illumina.com/content/dam/illumina-support/documents/documentation/software_documentation/genomestudio/genomestudio-2-0/genomestudio-genotyping-module-v2-user-guide-11319113-01.pdf).
- Required files:
  - Sample sheet: as csv file (created above).
  - Data repository: as idat files.
  - Manifest file: as bpm file.
  - Cluster file: as egt file.
- Data provided from Mylene Docquier, copied from sftp and saved here:  `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\data`.
- Create new IDs based on GPCR randomization (see `code/randomize_IDs.r`), and save to above folder as: `Eap0819_1t26_27to29corrected_7b9b_randomizedID.csv`.
- Note that original IDs can be found in the same folder at the file: `Eap0819_1t26_27to29corrected_7b9.csv`, if needed.
- Create empty folder here: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS`, named: `GS_project_26092019` (data of creation).
- Using new IDs, create genome studio project as follows:
  1. Open GenomeStudio.
  2. Select: File > New Genotyping Project.
  3. Select `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS` as project repository.
  4. Under project name: use "GS_project_26092019" and click "Next".
  5. Select "Use sample sheet to load intensities" and click "Next".
  6. Select sample, data and manifests as specified below and click "Next":
     - Sample sheet:  `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\data\Eap0819_1t26_27to29corrected_7b9b_randomizedID.csv`,
     - Data repository: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\data`,
     - Manifest repository: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\data`.
  7. Select "Import cluster positions from cluster file" and choose cluster file located here: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\data\GSPMA24v1_0-A_4349HNR_Samples.egt` and click "Finish".

- Genome studio files were created using the following required files:
  - Sample sheet: as csv file (created above).
  - Data repository: as idat files (provided from Mylene Docquier).
  - Manifest file: as bpm file (provided from Mylene Docquier).
  - Cluster file: as egt file (provided from Mylene Docquier).

## Part C: Clustering and PLINK conversion.

- Data saved on CHUV servers at the following location: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\GS_project_26092019`.
- `GS_project_26092019.bsc` was opened (requires Genome Studio) and used for clustering.
- Clustering was performed according to the guidelines in the webinar (see [notes on creating custom cluster files](create_custom_cluster_files.html)) with the following procedure:
  1. **Cluster**: cluster all SNPs, evaluate samples.
     1. Once data was opened, all SNPs were clustered by clicking "Cluster all SNPs button" in the top panel (icon with 3 red, purple, blue ovals). SNP statistics and heritability estimate updates were ignored.
     2. In the samples table (bottom left panel) call rate was recalculated by clicking "Calculate" (calculator icon) to recalculate SNP call rates with new cluster positions. SNP statistics and heritability estimate updates were ignored.
     3. The sample table was then sorted by the "Call Rate" column and samples with call rate <95% were selected and removed from downstream processing (right click, select "Exclude Selected Samples"), 8 samples fell below this cut-off. Updates were ignored. In "SNP Graph" right click and deselect "Show Excluded Samples".
  2. **Recluster**: cluster sex chromosomes, cluster autosomes.
     1. "SNP Table" was filtered by ("Chr" = Y) using filter icon.
     2. Using the 3rd and 7th SNP (index 3010 and 3014, 3 samples had missing values for 3010 and sex was determined to be female using 3014), males were selected as those with high intensities (females have no Y chromosome) and set to have an aux value of 101 by right clicking the selected samples in the "Samples Table". Similarly, females were selected and set to have an aux value of 102.
     3. "Samples Table" was filtered to have ("Aux" > 100).
     4. "Samples Table" was sorted on "Aux" column and females were selected (value 102) and excluded. Updates were ignored.
     5. In "SNP Table", all SNPs were selected and Y-snps were clustered (right click and "Cluster Selected SNPs") on only male samples. Updates were ignored.
     6. Females were re-added to the project in the "Samples Table".
     7. "SNP Table" was filtered by ("Chr" = X) using filter icon.
     8. In "Samples Table", males were selected (Aux value 101) and excluded. Updates were ignored.
     9. In "SNP Table", all SNPs were selected and X-SNPs were clustered (right click and "Cluster Selected SNPs") on only female samples. Updates were ignored.
     10. Males were re-added to the project in the "Samples Table".
     11. "SNP Table" was filtered by [ !("Chr" = X ) AND !("Chr" = Y ) ], using filter icon.
     12. In "SNP Table", all SNPs were selected and autosomal SNPs were clustered (right click and "Cluster Selected SNPs") on all good quality samples. Update SNP statistics.
     13. In the samples table (bottom left panel) call rate was recalculated by clicking "Calculate" (calculator icon) to recalculate SNP call rates with new cluster positions. SNP statistics and heritability estimate updates were ignored.
     14. SNP statistics were updated ("Analysis" > "Update SNP statistics").
  3. **Review and edit**: use filters and scores to evaluate SNPs, correct or zero SNPs as needed. No manual editing was performed.
- New genome studio was exported to the following location: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS`, and named:  `GS_project_26092019_cluster`.
- Remove filtered individuals:
  - In samples table, remove filter for "Aux" > 100.
  - Recalculate SNP statistics for these 8 samples only (to save time).
  - Note that sample call rates have increased with new clustering positions.
- Project was exported as PLINK file to the following location: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS`, and named: `PLINK_091019_0920`.
- Individual PLINK files within above folder were named according to parent directory as: PSYMETAB_GWAS.ped and PSYMETAB_GWAS.map.
- Ultimately, the final ped/map files reside here: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\PLINK_091019_0920`.

### Notes on GenomeStudio.
- Processing data within GS software is *slow* in comparison to the rest of the pipeline.
- There is no command line version, only a licensed, GUI version available.
- It is impossible to fully automate and/or parallelize.

### Data updates and releases.
- Initial data was received on April 8, 2019:
  - Final two plates were received on May 17, 2019.
  - Processing began with initial files.
- July 18, 2019 update:
  - It came to our attention that 15 participants were genotyped that did not consent.
  - This list was sent to Mylene to be removed.
  - Plates 27 to 29 were re-provided on 08/08/2019 without these 15 individuals (list below, and provided by Severine in email).
```{r eval=FALSE}
013CB
017CB
074CB
095CB
150CRV
192CRV
193CRV
156CSM
181CSM
191CSM
224UAS
234GL
058GP
246GP
089PP
```
  - Until new file was provided, these participants were removed using PLINK to avoid any further analysis of these individuals.
  - The new genomestudio file was copied to: `L:\PCN\UBPC\ANALYSES_RECHERCHE\Jenny\PSYMETAB_GWAS\PSYMETAB_GS2\Plates27to29_0819`.
  - The same process above was followed (data opened in GS, cluster positions imported, and data saved to `Plates27to29_0819_cluster`, and `PLINK_270819_0457`).
  - Old files were deleted to remove all data containing these individuals.
  - Updated files were then copied to PSYMETAB_GS1.
- August 28, 2019 update:
  - Mylene provided one single genome studio file with all samples (excluding the list from Severine).
  - These files were copied to UPPC folders and custom clustering was re-performed.
  - These changes are reflected in the above description.
  - All old files were subsequently deleted to ensure the data from these participants is completely removed from all databases.
  - As of September 3, 2019, all clustering was complete and final PLINK files (`PLINK_030919_0149`) were copied to SGG directory (names of plink files according to parent directory: `DATA`).
- September 6, 2019 update:
  - It was decided that all IDs part of PSYMETAB should be randomized to ensure they are not identifiable.
  - We had a meeting to discuss (Celine, Fred, Chin, Nermine, and Claire), and decided to use a CHUV program (GPCR) for the randomization process.
  - We requested with Mylene to create a new project with the new IDs, but she suggested to create our own GS project.
  - She provided all relevant data to create our own GS project.
  - The description above reflects these changes.
- As of October 11, all GS file were created, clustered and exported as PLINK files and subsequently moved to the sgg server.

## Part D: Copy files to SGG server.
- PLINK files were copied to SGG servers using FileZilla
- Host name: `je4649@hpc1.chuv.ch`
- Password: `<chuv-password>`
- Port: `22`
- Output saved to: `/data/sgg2/jenny/projects/PSYMETAB_GWAS/data/raw`.

*All subsequent steps were performed on the `sgg` server and run using `drake` plan*


# Step 2: Pre-quality control data prep.

**See `qc_prep` drake plan in [code/plans.sh](https://github.com/jennysjaarda/PSYMETAB/blob/master/code/plan.R).**  

- Processed sex and ethnicity files to be used in QC scripts.
- Sex file was created according to the input specified on plink man page (FID, IID, sex [M/F]).
- Ethnicity input file to be used in R script for comparison to genetically derived ethnic groups (by snpweights).
- Recodes ethnic groups as follows:
  - Changes French codes to English.
  - Changes missing to unknown.
  - Groups small ethnic groups to missing.
- A1 rsid conversion file was updated to remove all SNPs labeled with a [.] (see [data sources](data_sources.html)).
- Create duplicates file

# Step 3: Pre-imputation quality control.

*Results of Step 3-6 are saved to `analysis/QC`. The majority of analyses were performed using [`PLINK`](https://www.cog-genomics.org/plink/2.0/) (either version 2.0 or 1.9)*
*Each sub-spet (i.e. 0-15) corresponds to one folder within `analysis/QC`*

**Source code for Step 3 can be found at: [code/pre_imputation_qc.sh](https://github.com/jennysjaarda/PSYMETAB/blob/master/code/pre_imputation_qc.sh).**   

```{r setup, include = FALSE}
options(scipen=999)
source("code/packages.R")
source("code/functions.R")
source("code/settings.R")


library(R.utils)
library(kableExtra)
project_dir <- "/data/sgg2/jenny/projects/PSYMETAB"
output_name <- "PSYMETAB_GWAS"
input_chip <-plink_bed_out
sex_file <- read.table('data/processed/phenotype_data/PSYMETAB_GWAS_sex.txt', header=F)
loadd(dups)
```


```{r missingness_vars, include = FALSE}
missingness_variants_removed <- countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_10.bim"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_10.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_05.bim"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_05.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_01.bim"))[1]
    
missingness_indiv_removed <- countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_10.fam"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_05.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_05.fam"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_01.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness.step3.fam"))[1]
    
initial_variants <- countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.bim"))[1]
initial_ind <- countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.fam"))[1]
```

## 0. Preprocessing.

1. Create binary PLINK files (if necessary):
    - `r countLines(paste0(input_chip, ".bim"))` variants initially.
    - `r countLines(paste0(input_chip, ".fam"))` individuals initially.
2. Exclude Y and MT variants:
    - `r countLines(paste0("analysis/QC/00_preprocessing/non_autosome_or_x_variants"))` Y / MT variants removed.
    - `r countLines(paste0("analysis/QC/00_preprocessing/temp1.bim"))` variants remaining.
3. Remove duplicate variants:
    - `r countLines(paste0("analysis/QC/00_preprocessing/duplicate_variants"))` duplicates removed.
    - `r countLines(paste0("analysis/QC/00_preprocessing/temp2.bim"))` variants remaining.
4. Update sex:
    - Using the file located at: `data/processed/phenotype_data/PSYMETAB_GWAS_sex.txt` (created above).
    ```{r init_sex, echo = FALSE}
    table(sex_file[,3])
    ```
5. Remove duplicate individuals that were identified previously (i.e. two different IDs for the same participant):
    - `r length(dups$dups)` duplicates identified and removed
    - `r countLines(paste0("analysis/QC/00_preprocessing/", study_name, ".preprocessing.step0.fam"))` indviduals remaining.
6. Sanity check: ensure that duplicates have the same genetic info"
    - From the PLINK [webpage](https://www.cog-genomics.org/plink/2.0/distance#make_king): *Note that KING kinship coefficients are scaled such that duplicate samples have kinship 0.5, not 1. First-degree relations (parent-child, full siblings) correspond to ~0.25, second-degree relations correspond to ~0.125, etc.*
    - If all duplicate ID samples have KINSHIP ~0.5, then indeed they are genetic duplicates. 
        
```{r duplicates, echo = FALSE}
t <- read.table(  paste0("analysis/QC/00_preprocessing/", study_name, ".duplicates.kin0"))
colnames(t) <- c('#FID1', 'ID1', 'FID2', 'ID2', 'NSNP', 'HETHET', 'IBS0', 'KINSHIP')
t
```


\newline
## 1. Strand alignment (so all SNPs are on positive strand).

1. Update chromosome
2. Update position
3. Flip alleles on negative strand
4. Extract SNPs that are not in strand file
5. Remove any non autosomal / X chromosomal variants (might have changed due to the pos and chr update):
    - `r countLines(paste0("analysis/QC/01_strandflip/non_autosome_or_x_variants"))` duplicates removed.
    - `r countLines(paste0("analysis/QC/01_strandflip/temp5.bim"))` variants remaining.
6. Update rsids using `data/processed/reference_files/rsid_conversion.txt`
7. Remove duplicate variants:
    - `r countLines(paste0("analysis/QC/01_strandflip/duplicate_variants"))` duplicates removed.
    - `r countLines(paste0("analysis/QC/01_strandflip/", study_name, ".strandflip.step1.bim"))` variants remaining.

\newline
## 2. Removal of SNPs that have MAF zero.

1. Calculate frequency of all SNPs
2. Remove MAF 0 SNPs: 
    - `r countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero_snp.txt"))` variants with `MAF = 0`.
    - `r countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.bim"))` variants remaining.

\newline
## 3. Missingness.

1. Exclude variants with >10% missingness (using `geno --0.1`): 
    - `r countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_10.bim"))[1]` variants removed.
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_10.bim"))` variants remaining.
2. Exclude individuals with >10% missingness (using `mind --0.1`): 
    - `r countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_10.fam"))[1]` individuals removed.
      - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_10.fam"))` individuals remaining.
3. Exclude variants with >5% missingness (using `geno --0.05`): 
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_10.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_05.bim"))[1]` variants removed.
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_05.bim"))` variants remaining.
4. Exclude individuals with >5% missingness (using `mind --0.05`): 
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_05.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_05.fam"))[1]` individuals removed.
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_05.fam"))` individuals remaining.
5. Exclude variants with >1% missingness (using `geno --0.01`): 
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_05.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_01.bim"))[1]` variants removed.
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_01.bim"))` variants remaining.
6. Exclude individuals with >1% missingness (using `mind --0.01`): 
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_01.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness.step3.fam"))[1]` individuals removed.
    - `r countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness.step3.fam"))` individuals remaining.
        
\newline
**Total removed: `r countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_10.bim"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_10.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_05.bim"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_05.bim"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_01.bim"))[1]` variants (`r formatC(round(missingness_variants_removed*100/initial_variants, 2), format='f', digits=2)`%) and `r countLines(paste0("analysis/QC/02_maf_zero/", study_name, ".maf_zero.step2.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_10.fam"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_05.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_mind_05.fam"))[1] + countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness_geno_01.fam"))[1] - countLines(paste0("analysis/QC/03_missingness/", study_name, ".missingness.step3.fam"))[1]` individuals (`r formatC(round(missingness_indiv_removed*100/initial_ind, 2), format='f', digits=2)`%).**

\newline
## 4. Sex check.

1. Perform sex check. 
2. Remove unambiguous sex violations. 
    - `r countLines(paste0("analysis/QC/04_sexcheck/", study_name, ".sexcheck.problem.ids"))[1]` individuals removed.
    - `r countLines(paste0("analysis/QC/04_sexcheck/", study_name, ".sexcheck.step4.fam"))` individuals remaining.
    
## 5. Imputation preparation.

1. Write frequency of final QC'd file (from #4) to file (using `-- freq`).
2. Using [McCarthy Group Tools](https://www.well.ox.ac.uk/~wrayner/tools/), QC'd files were prepared for imputation using the script [`HRC-1000G-check-bim-NoReadKey.pl`](https://www.well.ox.ac.uk/~wrayner/tools/HRC-1000G-check-bim-v4.2.11-NoReadKey.zip) (download link).
    - This script checks: Strand, alleles, position, Ref/Alt assignments and frequency differences.
    - Produces: A set of plink commands to update or remove SNPs based on the checks as well as a file (FreqPlot) of cohort allele frequency vs reference panel allele frequency.
    - Updates: Strand, position, ref/alt assignment.
    - Removes: A/T & G/C SNPs if MAF > 0.4, SNPs with differing alleles, SNPs with > 0.2 allele frequency difference (can be removed/changed in V4.2.2), SNPs not in reference panel
3. Replace underscores in fam file since vcf conversion uses understcores between `FID` and `IID`.
4. Run the generated `Run-plink.sh` script from #2.
5. Sort outputed `vcf` files.
6. Download zipped files to personl or CHUV files to copy to [Michigan Imputation Server](https://imputationserver.sph.umich.edu/index.html).

\newline
# Step 4: Imputation.

**Source code for Step 4 can be found at: [code/download_imputation.sh](https://github.com/jennysjaarda/PSYMETAB/blob/master/code/pre_imputation_qc.sh) and [code/check_imputation.sh](https://github.com/jennysjaarda/PSYMETAB/blob/master/code/check_imputation.sh).**

## 6. Run and download imputation.

1. Upload downloaded QC'd `vcf.gz` files to [Michigan Imputation Server](https://imputationserver.sph.umich.edu/index.html) as follows:
    - Select `Run`, `Genotype Imputation (Minimac4)`.
    - Reference panel: `HRC r1.1 2016 (GRCh37/hg19)`.
    - Array build: `GRCh37/hg19`.
    - rsq Filter: `off`.
    - Phasing: `Eagle v2.4 (phased output)`.
    - Population: `EUR`.
    - Mode: `Quality Control & Imputation`.
  ![](assets/michigan_imputation_screenshot_03022020.PNG)

\newline
2. Download imputation, using password from email retrieve the following files:
    - [QC report](generated_reports/qcreport.html).
    - QC stats.
    - Logs.
    - Imputation results.
\newline

```{r imputed_variants, echo = FALSE}

list.files("analysis/QC//06_imputation_get/")

imputed_var <- numeric()
for (chr in 1:22){

  temp <- countLines(paste0("analysis/QC/06_imputation_get/chr", chr, ".info.gz"))[1] - 1
  temp <- cbind(chr, temp)
  imputed_var <- rbind(imputed_var, temp)

}
total <- cbind("all", sum(imputed_var[,2]))
imputed_var <- rbind(imputed_var, total)
colnames(imputed_var) <- c("Chr", "Num imputed variants")
imputed_var <- as.data.frame(imputed_var)
imputed_var
```


\newline
## 7. Check imputation.

- Using Will Rayner's [post imputation tool](https://www.well.ox.ac.uk/~wrayner/tools/Post-Imputation.html), produce a visual summary of the imputated results from the Michigan Imputation Server:
    - [Imputation report](generated_reports/07_imputation_check.html).
    - [Cross cohort report](generated_reports/CrossCohortReport.html).

\newline

# Step 5: Post imputation quality control.

## 8. PLINK conversion.

**Source code for Step 5 can be found at: [code/post_imputation_qc.sh](https://github.com/jennysjaarda/PSYMETAB/blob/master/code/post_imputation_qc.sh).**

1. Remove SNPs with `info < 0.30`
```{r filtered_imputed_var, echo = FALSE}

imputed_var[, "R2 filtered"] <- NA
for (chr in 1:22){

  temp <- countLines(paste0("analysis/QC/08_plink_convert/chr", chr, "/chr", chr, ".pvar"))[1] - 14
  imputed_var[["R2 filtered"]][chr] <- temp

}
total_temp <- sum(imputed_var[1:22,3])
imputed_var[["R2 filtered"]][23] <- total_temp
imputed_var
```

2. Update `bim` file to include rsIDs instead of `chr:bp` convention:
    - Output of Michigan Impuation server is  in format `chr:bp:ref:alt`.
    - Convenient to have SNPs in regular rsIDs for extraction, etc.
    - If there is no known rsID, SNP name is left as `chr:bp:ref:alt`.
    - Reference file for determining rsIDs can be found here: `/data/sgg2/jenny/data/dbSNP/dbSNP_SNP_list_chr${chr}.txt`, which was processed according to description in `jenny/SGG_generic/scripts/public_data.sh`.

\newline
## 9. Extract typed SNPs.

1. Write a list of only genotypd data to run in snpweights software (using `require=info "TYPED"` flag).
```{r typed_snps, echo = FALSE}

imputed_var[, "Typed SNPs"] <- NA
for (chr in 1:22){

  temp <- countLines(paste0("analysis/QC/09_extract_typed/chr", chr, "/temp1.pvar"))[1] - 14
  imputed_var[["Typed SNPs"]][chr] <- temp

}
total_temp <- sum(imputed_var[1:22,4])
imputed_var[["Typed SNPs"]][23] <- total_temp
imputed_var
```
2. Hard call back to genotypes (`bim`, `bed`, and `fam` files) using the `--hard-call-threshold` flag set at `0.1`.
3. Merge by chromosome genotyped data into single file.

\newline
## 10. Merge imputed SNPs.

1. Convert fileset from step #8 back to `vcf` as there is no merge function in plink (using the flag `--recode vcf id-paste=iid vcf-dosage=HDS`).
2. Merge using `bcftools concat`.
3. Convert back to pgen using `plink2 --vcf <output-name> dosage=HDS`.
